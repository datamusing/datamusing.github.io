<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Musings in Amusing Data]]></title>
  <link href="http://datamusing.github.io/atom.xml" rel="self"/>
  <link href="http://datamusing.github.io/"/>
  <updated>2015-01-16T01:09:19-08:00</updated>
  <id>http://datamusing.github.io/</id>
  <author>
    <name><![CDATA[Sudeep Das]]></name>
    <email><![CDATA[datamusing@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Implicit Feedback and Collaborative Filtering]]></title>
    <link href="http://datamusing.github.io/blog/2015/01/07/implicit-feedback-and-collaborative-filtering/"/>
    <updated>2015-01-07T00:15:33-08:00</updated>
    <id>http://datamusing.github.io/blog/2015/01/07/implicit-feedback-and-collaborative-filtering</id>
    <content type="html"><![CDATA[<p>SAN FRANCISCO, CA — I have been re-reading  <a href="http://dl.acm.org/citation.cfm?id=1511352" title="Implicit Feedback Paper">this classic paper</a>, and was impressed both by its clarity and simplicity. <!-- more --> </p>
<blockquote><p>Often the most powerful ideas are also the most elegant!</p></blockquote>
<p>Here, I will try to summarize the technique, with just enough math thrown in to facilitate understanding from a coding perspective. 
 <script type="math/tex">\def\RR{\bf R}</script>
<script type="math/tex">\def\bx{\bf{x}}</script>
<script type="math/tex">\def\by{\bf{y}}</script>
<script type="math/tex">\renewcommand{\bra}[1]{\left\langle{ #1}\right\vert}</script>
<script type="math/tex">\renewcommand{\bbra}[1]{\left\langle{ #1}\right.}</script>
<script type="math/tex">\renewcommand{\ket}[1]{\left\vert{ #1}\right\rangle}</script></p>

<p><img class="-responsive" src="https://dl.dropboxusercontent.com/u/18915298/blog/implicitCollab/implicit_small.png" /></p>

<p><strong>Good Old Explicit</strong></p>

<p>The classic problem of collaborative filtering (CF) is the one with explicit feedback: given a set of users <script type="math/tex">u</script> and items <script type="math/tex">i</script> observe the user-item interaction explicitly through, say, a rating <script type="math/tex">r_{ui}</script>, and then predict the ratings for the user-item pairs that are unknown. If we have <script type="math/tex">m</script> users and <script type="math/tex">n</script> items, we can envision an <script type="math/tex">m\times n</script> ratings matrix <script type="math/tex">\bf{R}</script> such that each row corresponds to a given user and non-empty elements in that row correspond to the ratings that this user has given to 
the items. Because each user would typically rate a small proportion of the items, this matrix will be sparse. </p>

<p>The aim of  Recommender Systems is to fill in the blanks of this matrix with predicted ratings using the information at hand: <em>matrix completion</em>. The popular method of accomplishing this is through matrix factorization whereby the ratings matrix (that can routinely be a million users by a million items) is expressed as a product of two lower dimensional matrices, a user-features matrix and a item-features matrix. Typically, one uses 50-200 features. </p>

<p>Let us introduce a bit of notation. I borrow a bit of notation from quantum mechanics and write vectors as <script type="math/tex">\vert \bx \rangle</script>, such that it understood to be a column vector. This simplifies some algebraic manipulations later. The latent feature vector of user <script type="math/tex">u</script> is denoted as: </p>

<script type="math/tex; mode=display">\ket{ \bx_u} \equiv \begin{bmatrix} x_u^0 \\ x_u^1 \\ ... \\x_u^{f-1} \end{bmatrix}</script>

<p>where the superscripts denote the indices of the elements. 
Its transpose is denoted by the row vector:</p>

<script type="math/tex; mode=display">\bra{\bx_u} \equiv {\bx_u}^{T}\equiv \begin{bmatrix} x_u^0,  x_u^1, ..., x_u^{f-1} \end{bmatrix}  </script>

<p>so that the squared norm can be written as the inner product: <script type="math/tex"> \bbra{\bx_u}\ket{\bx_u}</script>. 
Similarly, we can write the latent feature vector for item <script type="math/tex">i</script>, as </p>

<script type="math/tex; mode=display"> \ket{ \by_i} \equiv \begin{bmatrix} y_i^0 \\ y_i^1 \\ ... \\y_i^{f-1} \end{bmatrix}</script>

<p>The problem is formulated in terms of minimizing an objective function defined as a sum of residuals from knows ratings:</p>

<script type="math/tex; mode=display">\min_{x_*, y_*} \sum_{u,i; \text{ $r_{ui}$ known}}\left(r_{ui} -\bbra{\bx_u}\ket{\by_i}\right)^2 + \lambda (\bbra{\bx_u}\ket{\bx_u} + \bbra{\by_i}\ket{\by_i}  ) </script>

<p>In other words, solve for the latent factors until the squared difference between the explicit and predicted ratings is minimized. The <script type="math/tex">\lambda</script> term adds regularization to prevent overfitting. By merit of the sparsity of the ratings matrix this problem can be efficiently solved, typically using a Stochastic Gradient Descent type algorithm. </p>

<h2 id="why-implicit">Why Implicit?</h2>

<p>The sparsity of the ratings matrix is a good thing, but it is also its problem. In most settings, it is very hard to get a large fraction of users rate a large fraction of the items. So there might just be too little signal if we stuck to explicit ratings only. However the user item interaction can happen in the many different ways other than a rating. A user may be searching for an item (say a restaurant) on the web, or listening to/skipping a track, or clicking on links in an email campaign. and so on and so forth. Usually this type of implicit signals show the attachment of an user to an item through some sort of frequency.  These actions do not explicitly state or quantify any preference of the user for the item, but instead gives us confidence about the user’s opinion. And we usually have plenty more of these signals than explicit ratings. </p>

<p>Consider, for example, listening behavior to songs. When I listen to music on a streaming service, I rarely ever rate a song that I like or dislike. But more often I skip a song, or listen only halfway through it if dislike it. If I really like a song, I come back to it often. Even if I would like to rate a song, sometimes it is simply not possible, as I might be driving, or the song might be playing through sonos, roku or some system which does not allow for a easy rating interface. So, to infer my musical taste profile, my listens, my repeat listens, my skips, and fraction of tracks listened to, etc. are far more valuable signals than explicit ratings. This is what this paper attempted to incorporate within the CF framework.</p>

<h2 id="the-formulation">The Formulation</h2>

<p>To keep it concrete, let us continue with the music streaming example, and lets say that we are only going to use the number of times a user has listened to a track (track listen count) as the only signal. For user <script type="math/tex">u</script> and track <script type="math/tex">i</script>, let us reuse <script type="math/tex">r_{ui}</script> to denote that number. We begin by defining a <em>preference</em> <script type="math/tex">p_{ui}</script> of the user <script type="math/tex">u</script> to track <script type="math/tex">i</script> such that it is unity when the user has at least one listen and zero if the user has not interacted with the track at all:</p>

<script type="math/tex; mode=display">% &lt;![CDATA[
p_{ui} = \begin{cases} 1. &\mbox{if } r_{ui} > 0 \\ 0. & \mbox{otherwise}. \end{cases} . %]]&gt;</script>

<p>So, at the end, the task of the recommendation system will be to predict the preference for the unseen tracks. Next, we use the track listen count to define a <em>confidence</em> <script type="math/tex">c_{ui}</script> of the liking of the track by the user:</p>

<script type="math/tex; mode=display">c_{ui} =  1 + \alpha r_{ui} .</script>

<p>This is done in sort of an ad hoc way, and the confidence could de  defined in many other ways as long as it is a monotonic function of the frequency.  The confidence has a base value of <script type="math/tex">1</script> for all user-item pairs and it gets stronger as the number of listens increase. So a high value of confidence <script type="math/tex">c_{ui}</script> would mean that for that user-track pair these is a lot less noise about the preference of that particular user to that track. Therefore, it means that it is more important for the algorithm to predict a preference closer to unity for the pairs where the confidence is high. This leads to the following analog of explicit objective function minimization problem:</p>

<script type="math/tex; mode=display"> \min_{x_*, y_*} \sum_{u,i} c_{ui} \left( p_{ui} - \bbra{\bx_u}\ket{\by_i} \right)^2 + \lambda\left(\sum_u \bbra{\bx_u}\ket{\bx_u} + \sum_i \bbra{\by_i}\ket{\by_i} \right) . </script>

<p>A big <script type="math/tex">c_{ui}</script> means that the prediction <script type="math/tex">\bbra{\bx_u}\ket{\by_i}</script> has to be that much closer to <script type="math/tex">p_{ui}</script> for that term not to contribute a lot to the sum.</p>

<p>But suddenly now, the problem is no longer sparse, and the sum contains all <script type="math/tex">m\times n</script> terms. </p>

<p><strong>How to solve this, then? </strong></p>

<p>Linear algebra tricks come to the rescue! </p>

<p>First, note that if the user latent factors are held constant the problem is quadratic in the item latent factors, and vice versa. 
This leads to the alternating least squares  (ALS) approach for this problem. But that by itself does not solve the  lack of sparsity issue. </p>

<p>The ALS proceeds in two steps:</p>

<p><em>STEP 1 of ALS:</em> First, we hold the item latent vectors <script type="math/tex">\ket{\by_i}</script> fixed, and solve for the user latent vectors <script type="math/tex">\ket{\bx_u}</script>. For a given user <script type="math/tex">u_0</script>, the optimization function can be re-written in the matrix notation. 
First we define a <script type="math/tex">n\times f</script> item-factor matrix as:</p>

<script type="math/tex; mode=display">\bf{Y} = \begin{bmatrix} \bra{\by_0} \\ \bra{\by_1}\\ ... \\ \bra{\by_{n-1}} \end{bmatrix}</script>

<p>Next, we define a vector of preferences for the user <script type="math/tex">u_0</script> as: </p>

<script type="math/tex; mode=display">\ket{ {\bf{p}}_{u_0} } =  \begin{bmatrix} p_{u_{00} }  \\ p_{u_{01} }\\ ... \\  p_{u_{0 (n-1) }  }  \end{bmatrix}</script>

<p>and an <script type="math/tex">n \times n</script> diagonal matrix of confidence in items for this user <script type="math/tex"> {\bf C}^{u_0} </script>  as:</p>

<script type="math/tex; mode=display">% &lt;![CDATA[
 {\bf C}^{u_0} = \begin{bmatrix} c_{u_{00}} & 0 & 0 & 0 & ... & 0 \\ 0 & c_{u_{01}} & 0 & 0 & ... &0\\ ... \\ ... \\ 0 & 0 & 0 & 0 & ... & c_{u_{0 (n-1) }}\end{bmatrix}. %]]&gt;</script>

<p>With these, the relevant part of the objective function can be rewritten as:</p>

<script type="math/tex; mode=display"> \left[\left(\ket{ {\bf p}_{u_0}} - {\bf Y} \ket{ \bx_{u_0}} \right)^T {\bf C}^{u_0}\left(\ket{ {\bf p}_{u_0} } - {\bf Y} \ket{ \bx_{u_0} } \right) \right] + \lambda \bbra{\bx_{u_0}}\ket{\bx_{u_0}}. </script>

<p>To minimize this, we set the derivative w.r.t. <script type="math/tex">\ket{ \bx_{u_0}}</script> to zero, and we find the solution (see derivation at the bottom) as</p>

<script type="math/tex; mode=display"> \ket{ \bx_{u_0}} = \left( {\bf Y}^T {\bf C}^{u_0} {\bf Y} + \lambda  {\bf I}  \right)^{-1}  {\bf Y}^{T} {\bf C}^{u_0} \ket{ {\bf p}_{u_0}}. \text{..... (1)}</script>

<p><em>STEP 2 of ALS:</em> In the next step, in an exactly analogous fashion, we can hold the user latent vectors fixed and vary the item latent vectors to minimize the cost function. We define an <script type="math/tex">m\times f</script> user-factor matrix <script type="math/tex">{\bf X}</script>, an <script type="math/tex">m\times m</script> diagonal matrix <script type="math/tex">{\bf C}^{i_0}</script>, and a preference vector <script type="math/tex">\ket{ {\bf p}_{i_0}}</script> for all users against item <script type="math/tex">i_0</script>. We end up with the solution: </p>

<script type="math/tex; mode=display">\ket{ \by_{i_0}} = \left( {\bf X}^T {\bf C}^{i_0} {\bf X} + \lambda  {\bf I}  \right)^{-1}  {\bf X}^{T} {\bf C}^{i_0} \ket{ {\bf p}_{i_0}}.  \text{..... (2)} </script>

<p>The algorithm then alternates between STEP 1 and STEP 2 until the latent factors converge (usually <script type="math/tex">\sim 10</script> sweeps). </p>

<p><strong>Computational Complexity </strong></p>

<p>Going back to STEP 1, we first note that where <script type="math/tex">{\bf C}^{u}_{ii}</script> is unity <script type="math/tex">p_{ui}</script> is zero by construction. Therefore for each of the <script type="math/tex">m</script> users, <script type="math/tex">{\bf C}^{u} \ket{ {\bf p}_{u}}</script> has only <script type="math/tex">n_u</script> non-zero terms where <script type="math/tex">n_u</script> are the number of items for which the user <script type="math/tex">u</script> has preference equal to unity, and typically <script type="math/tex">n_u  \ll n</script>. The main bottleneck is the term <script type="math/tex"> {\bf Y}^T {\bf C}^{u} {\bf Y}</script> whose naïve calculation would require time <script type="math/tex">O(f^2 n)</script> for each user. Speedup can be obtained just by rewriting this term as</p>

<script type="math/tex; mode=display">{\bf Y}^T {\bf C}^{u} {\bf Y} =  {\bf Y}^T\left({\bf C}^u - {\bf I}\right) {\bf Y} + {\bf Y}^T {\bf Y}. </script>

<p>The beauty of this expression is that the <script type="math/tex">f\times f</script> matrix <script type="math/tex">{\bf Y}^T {\bf Y}</script> has to be calculated only once (being independent of the user), and <script type="math/tex">\left({\bf C}^u - {\bf I}\right)</script> is non-zero for only those <script type="math/tex">n_u</script> items that the user has expressed any preference for! Therefore this part of the calculation reduces vastly in complexity to <script type="math/tex">O(f^2 n_u)</script> for each of the <script type="math/tex">m</script> users. </p>

<p>An analogous trick works for STEP 2 as well! </p>

<p>Once the solution converges, the predicted preference of a user for an item can be computed as</p>

<script type="math/tex; mode=display"> \hat{p}_{ui} = \bbra{\bx_u}\ket{\by_i}.</script>

<p>Sort the tracks by this value, and voila, you have recommended tracks for every listener in your sample! </p>

<p><strong>Another Trick! </strong></p>

<p>Suppose there are 100 million songs. If we are using 200 features, then <script type="math/tex">{\bf Y}</script> has dimension <script type="math/tex">10^8 \times 200</script>. 
Therefore, <script type="math/tex">{\bf Y}^T {\bf Y}</script> is not a trivial multiplication. Conventional matrix multiplication will take a row of <script type="math/tex">{\bf Y}^T</script> that is 100 million wide and multiply it with a column of <script type="math/tex">{\bf Y}</script> that is also 100 million tall. Such computations can be costly and slow. However the way we wrote down <script type="math/tex">{\bf Y}</script> in terms of the vectors <script type="math/tex">\ket{\by}</script> gives us another way to compute this: 
<script type="math/tex">% &lt;![CDATA[
{\bf Y}^T {\bf Y} = \begin{bmatrix} \ket{\by_0} & \ket{\by_1} & ... & \ket{\by_{n-1}} \end{bmatrix}  \begin{bmatrix} \bra{\by_0} \\ \bra{\by_1}\\ ... \\ \bra{\by_{n-1}} \end{bmatrix}\\ = \ket{\by_0}\bra{\by_0}  +  \ket{\by_1}\bra{\by_1} + ...+ \ket{\by_{n-1}}\bra{\by_{n-1}}  %]]&gt;</script> 
i.e. the matrix product is the sum of the outer products of the rows, each of which is <script type="math/tex">200 \times 200</script> and being independent of each other can be computed on different nodes and then added back together! </p>

<p><strong>Quick derivation of the update rule </strong></p>

<p>We expand the cost function by propagating the transpose and then multiplying through :</p>

<script type="math/tex; mode=display">\left[\left(\ket{ {\bf p}_{u_0} } - {\bf Y} \ket{\bx_{u_0}} \right)^T {\bf C}^{u_0}\left(\ket{ {\bf p}_{u_0}} - {\bf Y} \ket{ \bx_{u_0}} \right) \right] + \lambda \bbra{\bx_{u_0}}\ket{\bx_{u_0}} \\ = \left(\bra{ {\bf p}_{u_0}} - \bra{\bx_{u_0}}{\bf Y}^T \right) {\bf C}^{u_0}\left(\ket{ {\bf p}_{u_0}} - {\bf Y} \ket{\bx_{u_0}} \right)  + \lambda \bbra{\bx_{u_0}}\ket{ \bx_{u_0}} \\ = \bra{ {\bf p}_{u_0}}  {\bf C}^{u_0} \ket{ {\bf p}_{u_0}}  - \bra{\bx_{u_0}} {\bf Y}^T {\bf C}^{u_0} \ket{ {\bf p}_{u_0}} - \bra{ {\bf p}_{u_0}}  {\bf C}^{u_0} {\bf Y} \ket{ \bx_{u_0}} +\bra{\bx_{u_0}}{\bf Y}^T {\bf C}^{u_0}  {\bf Y} \ket{ \bx_{u_0}}  + \lambda \bbra{\bx_{u_0}}\ket{\bx_{u_0}}  </script>

<p>Taking the derivative w.r.t. <script type="math/tex">\bra{ \bx_{u_0}} </script> and setting it to zero gives:</p>

<script type="math/tex; mode=display"> - {\bf Y}^T {\bf C}^{u_0} \ket{ {\bf p}_{u_0}} + {\bf Y}^T {\bf C}^{u_0}  {\bf Y} \ket{ \bx_{u_0}} + \lambda {\bf I} \ket{ \bx_{u_0}} = 0,</script>

<p>which implies</p>

<script type="math/tex; mode=display"> \left({\bf Y}^T {\bf C}^{u_0}  {\bf Y} + \lambda {\bf I} \right)\ket{\bx_{u_0}} =  {\bf Y}^T {\bf C}^{u_0} \ket{ {\bf p}_{u_0}} </script>

<p>that immediately gives us the solution (1) written above. </p>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-58361665-1', 'auto');
  ga('send', 'pageview');

</script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fun With Interactive Visualizations in Astrophysics]]></title>
    <link href="http://datamusing.github.io/blog/2014/09/03/the-case-for-interactive-visualizations-in-astrophysics/"/>
    <updated>2014-09-03T18:33:25-07:00</updated>
    <id>http://datamusing.github.io/blog/2014/09/03/the-case-for-interactive-visualizations-in-astrophysics</id>
    <content type="html"><![CDATA[<p>Recently, I have been playing  a lot with interactive data visualizations for my data science introspection work. While making these interactive plots, and experiencing their sheer power in expressing so many aspects of the data in clean and simple charts, I have often wondered how much more enriching such interactive visualizations would have been in my astrophysicist life.  <!--more-->  The most versatile tool for this purpose is undoubtedly the <a href="http://d3js.org/">d3.js</a> javascript library. There is a  steep learning curve in mastering d3, and honestly, I am climbing it right now. So maybe, it would have been a bit  too much to invest a lot of time in picking up this tool while I was busy writing code, papers and grant proposals.  </p>

<blockquote>
  <p>Luckily, it turns out that there are high level libraries that have been built on top of d3.js, which are way simpler to use, and in as little as half an hour, one could have a rich interactive plot up and running!  </p>
</blockquote>

<p>So, here is my attempt to  share that sliver of wisdom, so that you, my  esteemed astrophysicist colleague, can make plots like this pretty easily. I show a case study here with a recent data release from the South Pole Telescope collaboration. </p>

<h2 id="the--2500-square-degree-spt-sz-cluster-sample">The  2500 square-degree SPT-SZ Cluster Sample</h2>

<p>On September 2, 2014 the South Pole Telescope (SPT) collaboration published a paper on the arXiv entitled <em>Galaxy Clusters Discovered via the Sunyaev-Zel’dovich Effect in the 2500-square-degree SPT-SZ survey</em> <a href="http://arxiv.org/abs/1409.0850">(Bleem et al. 2014)</a>.  Incidentally, the work was led by Lindsey Bleem  whom I had the pleasure to interact with as  a fellow postdoc at the Argonne National Laboratory. </p>

<p><img class="right" src="https://dl.dropboxusercontent.com/u/18915298/blog/sptpaper/bleemEtAl.png" width="400" height="200" /></p>

<p>This paper represents solid work  of following up 677 Sunyaev-Zel’dovich (SZ) clusters detected (at more than 4.5-$\sigma$ significance) by the temperature decrements they cause in the 95 and 150 GHz cosmic microwave background (CMB) maps. To confirm  these detections,  ground- and space-based imaging  was used to find their optical and near-infrared (NIR) counterparts. In 516 of the 677 candidates, the counterparts were found and a redshift could be derived. Here is a plot from the paper showing the mass vs. redshift of these 516 clusters as black crosses. From each point on the figure, you can read off the the mass ($M_{500}$)  and the redshift of the cluster. But there is so much more information for each galaxy cluster: </p>

<ul>
  <li>the cluster ID</li>
  <li>the  detection significance ($\xi$)</li>
  <li>whether the cluster has an x-ray companion (XRAY)</li>
  <li>whether the cluster exhibits strong lensing (SL)</li>
  <li>the integrated Comptonization parameter, $Y_{SZ}$. </li>
  <li>the  core radius ($\theta_c$)  (a measure of the size of the central core)</li>
</ul>

<p>to name the most interesting ones. </p>

<p>So naturally, I was interested in  if we could put all this rich information into a single plot! <br />
I came up with two very quick versions of the visualization. They both have all the above info, but they are presented 
with different purposes in mind. </p>

<p>Here they are:</p>

<h2 id="visualization-1-i-am-more-interested-in-the-detection-significance-and-which-clusters-have-strong-lensing-andor-an-x-ray-counterparts">Visualization 1: I am more interested in the detection significance, and which clusters have strong lensing and/or an X-ray counterparts</h2>

<p>Mouse over each bubble to activate the tooltip. </p>

<iframe width="100%" height="600" frameborder="0" src="http://bl.ocks.org/datamusing/raw/d353dd63e013448727b4/" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" oallowfullscreen="" msallowfullscreen=""></iframe>

<p>What I have done in the above plot is make the size of the bubble for each cluster proportional to its detection significance. You can immediately see that  bubbles get bigger as you go higher in the plot (along the mass axis), showing that more massive clusters were detected much more easily (that is a characteristic of the SZ effect). Then, I also color coded the ones that have only SZ, SZ+SL, SZ+XRAY, and SZ+SL+XRAY so that you can quickly investigate the properties of any specific class of cluster (e.g. the strong lensing clusters). Note that all the other information are contained in the tooltip, as you hover over the cluster. </p>

<h2 id="visualization-2-i-am-more-interested-in-the-size-and-flux-of-the-clusters-and-visually-see-if-there-are-trends">Visualization 2: I am more interested in the size and flux of the clusters, and visually see if there are trends.</h2>

<iframe width="100%" height="600" frameborder="0" src="http://bl.ocks.org/datamusing/raw/19ed8e9811c11a4ed9be/" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" oallowfullscreen="" msallowfullscreen=""></iframe>

<p>In this case, I made the size of the cluster bubble proportional to, well, its size ($\theta_c$), and its color a hue of orange that deepens as the Comptonization parameter $Y_{SZ}$  increases. </p>

<p>You can visually appreciate here the fact that $Y_{SZ}$ increases as mass increases, and that fact is fairly insensitive to redshift (this is a very typical scaling relation of the SZ effect). You can also see that the low mass, low redshift clusters have larger core radii. If you have spent a lot of time with SZ clusters, you can appreciated various other relations in this plot,
which I am not going to belabor with here. Again, all other information is now neatly contained in the tooltip. </p>

<h1 id="do-it-yourself">Do It Yourself</h1>

<p>So, how do you quickly make this yourself! </p>

<p>Here is what I did:</p>

<ul>
  <li>For the data wrangling part I used Python.  I read in the data from the FITS file using <code>pyfits</code> and then processed it using <code>Pandas</code>. Then end result was a tab separated text file with 516 rows. </li>
  <li>For the visualization, I have used a library here called <a href="http://dimplejs.org/">dimple.js</a> that is a high level abstraction of the d3 library.  I pretty much took the <a href="http://dimplejs.org/examples_viewer.html?id=bubbles_standard">bubble chart example</a> and started modifying it. </li>
</ul>

<p>The code is essentially about 30 lines of html:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
</pre></td><td class="code"><pre><code class="html"><span class="line"><span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">&quot;chartContainer&quot;</span><span class="nt">&gt;</span>
</span><span class="line">  <span class="nt">&lt;script </span><span class="na">src=</span><span class="s">&quot;http://cdnjs.cloudflare.com/ajax/libs/d3/3.4.11/d3.min.js&quot;</span><span class="nt">&gt;&lt;/script&gt;</span>
</span><span class="line">  <span class="nt">&lt;script </span><span class="na">src=</span><span class="s">&quot;http://dimplejs.org/dist/dimple.v2.1.0.min.js&quot;</span><span class="nt">&gt;&lt;/script&gt;</span>
</span><span class="line">  <span class="nt">&lt;script </span><span class="na">type=</span><span class="s">&quot;text/javascript&quot;</span><span class="nt">&gt;</span>
</span><span class="line">    <span class="kd">var</span> <span class="nx">svg</span> <span class="o">=</span> <span class="nx">dimple</span><span class="p">.</span><span class="nx">newSvg</span><span class="p">(</span><span class="s2">&quot;#chartContainer&quot;</span><span class="p">,</span> <span class="mi">750</span><span class="p">,</span> <span class="mi">500</span><span class="p">);</span>
</span><span class="line">    <span class="nx">d3</span><span class="p">.</span><span class="nx">tsv</span><span class="p">(</span><span class="s2">&quot;spt_opt_labels.tsv&quot;</span><span class="p">,</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">data</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">      <span class="kd">var</span> <span class="nx">myChart</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">dimple</span><span class="p">.</span><span class="nx">chart</span><span class="p">(</span><span class="nx">svg</span><span class="p">,</span> <span class="nx">data</span><span class="p">);</span>
</span><span class="line">      <span class="nx">myChart</span><span class="p">.</span><span class="nx">setBounds</span><span class="p">(</span><span class="mi">95</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">600</span><span class="p">,</span> <span class="mi">445</span><span class="p">)</span>
</span><span class="line">      <span class="kd">var</span> <span class="nx">x</span> <span class="o">=</span> <span class="nx">myChart</span><span class="p">.</span><span class="nx">addMeasureAxis</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;REDSHIFT&quot;</span><span class="p">);</span>
</span><span class="line">      <span class="kd">var</span> <span class="nx">y</span> <span class="o">=</span> <span class="nx">myChart</span><span class="p">.</span><span class="nx">addMeasureAxis</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="s2">&quot;M500 (1e14)&quot;</span><span class="p">);</span>
</span><span class="line">      <span class="kd">var</span> <span class="nx">z</span> <span class="o">=</span> <span class="nx">myChart</span><span class="p">.</span><span class="nx">addMeasureAxis</span><span class="p">(</span><span class="s2">&quot;z&quot;</span><span class="p">,</span> <span class="s2">&quot;XI&quot;</span><span class="p">);</span>
</span><span class="line">      <span class="kd">var</span> <span class="nx">s</span> <span class="o">=</span> <span class="nx">myChart</span><span class="p">.</span><span class="nx">addSeries</span><span class="p">([</span><span class="s2">&quot;SPT_ID&quot;</span><span class="p">,</span><span class="s2">&quot;M500 (1e14)&quot;</span><span class="p">,</span><span class="s2">&quot;THETA_CORE&quot;</span><span class="p">,</span><span class="s2">&quot;YSZ&quot;</span><span class="p">,</span><span class="s2">&quot;XI&quot;</span><span class="p">,</span><span class="s2">&quot;LABEL&quot;</span><span class="p">],</span> <span class="nx">dimple</span><span class="p">.</span><span class="nx">plot</span><span class="p">.</span><span class="nx">bubble</span><span class="p">);</span>
</span><span class="line">      <span class="nx">s</span><span class="p">.</span><span class="nx">getTooltipText</span> <span class="o">=</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">e</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">                <span class="k">return</span> <span class="p">[</span>
</span><span class="line">                    <span class="s2">&quot;Cluster ID: &quot;</span> <span class="o">+</span> <span class="nx">e</span><span class="p">.</span><span class="nx">aggField</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
</span><span class="line">                    <span class="s2">&quot;Mass M500 (x 10^14) = &quot;</span> <span class="o">+</span> <span class="nb">parseFloat</span><span class="p">(</span><span class="nx">e</span><span class="p">.</span><span class="nx">aggField</span><span class="p">[</span><span class="mi">1</span><span class="p">]).</span><span class="nx">toFixed</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
</span><span class="line">                    <span class="s2">&quot;Core radius: &quot;</span> <span class="o">+</span> <span class="nb">parseFloat</span><span class="p">(</span><span class="nx">e</span><span class="p">.</span><span class="nx">aggField</span><span class="p">[</span><span class="mi">2</span><span class="p">]).</span><span class="nx">toFixed</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
</span><span class="line">                    <span class="s2">&quot;Y_SZ = &quot;</span> <span class="o">+</span> <span class="nb">parseFloat</span><span class="p">(</span><span class="nx">e</span><span class="p">.</span><span class="nx">aggField</span><span class="p">[</span><span class="mi">3</span><span class="p">]).</span><span class="nx">toExponential</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
</span><span class="line">                    <span class="s2">&quot;Detection significance = &quot;</span><span class="o">+</span><span class="nb">parseFloat</span><span class="p">(</span><span class="nx">e</span><span class="p">.</span><span class="nx">aggField</span><span class="p">[</span><span class="mi">4</span><span class="p">]).</span><span class="nx">toFixed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span class="line">                <span class="p">];</span>
</span><span class="line">      <span class="p">};</span>
</span><span class="line">
</span><span class="line">      <span class="nx">z</span><span class="p">.</span><span class="nx">overrideMax</span> <span class="o">=</span> <span class="mf">150.0</span><span class="p">;</span>
</span><span class="line">      <span class="kd">var</span> <span class="nx">myLegend</span> <span class="o">=</span> <span class="nx">myChart</span><span class="p">.</span><span class="nx">addLegend</span><span class="p">(</span><span class="mi">540</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="s2">&quot;right&quot;</span><span class="p">);</span>
</span><span class="line">      <span class="nx">myLegend</span><span class="p">.</span><span class="nx">fontSize</span> <span class="o">=</span> <span class="s2">&quot;10px&quot;</span><span class="p">;</span>
</span><span class="line">      <span class="nx">myChart</span><span class="p">.</span><span class="nx">assignColor</span><span class="p">(</span><span class="s2">&quot;SZ+SL+XRAY&quot;</span><span class="p">,</span> <span class="s2">&quot;#a6611a&quot;</span><span class="p">,</span><span class="mf">0.8</span><span class="p">);</span>
</span><span class="line">      <span class="nx">myChart</span><span class="p">.</span><span class="nx">assignColor</span><span class="p">(</span><span class="s2">&quot;SZ+XRAY&quot;</span><span class="p">,</span> <span class="s2">&quot;#dfc27d&quot;</span><span class="p">);</span>
</span><span class="line">      <span class="nx">myChart</span><span class="p">.</span><span class="nx">assignColor</span><span class="p">(</span><span class="s2">&quot;SZ&quot;</span><span class="p">,</span> <span class="s2">&quot;#80cdc1&quot;</span><span class="p">);</span>
</span><span class="line">      <span class="nx">myChart</span><span class="p">.</span><span class="nx">assignColor</span><span class="p">(</span><span class="s2">&quot;SZ+SL&quot;</span><span class="p">,</span> <span class="s2">&quot;#018571&quot;</span><span class="p">);</span>
</span><span class="line">      <span class="nx">myChart</span><span class="p">.</span><span class="nx">draw</span><span class="p">();</span>
</span><span class="line">    <span class="p">});</span>
</span><span class="line">  <span class="nt">&lt;/script&gt;</span>
</span><span class="line"><span class="nt">&lt;/div&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>And that is all you need, to produce this powerful graphic!</p>

<h2 id="learning-by-example">Learning by example</h2>

<p>To get started I would suggest downloading the html file and the tsv file that I have made availably publicly.<br />
Here is my <a href="https://gist.github.com/datamusing/d353dd63e013448727b4">gist</a>.</p>

<p>The steps:</p>

<ul>
  <li>Clone my gist using</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">$ git clone https://gist.github.com/d353dd63e013448727b4.git</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>Inside the gist directory, you will find all necessary files. The main file to look at is  <code>index.html</code></li>
  <li>Fire up a server from inside that directory using:</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">$ python -m SimpleHTTPServer 9999</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>Point your browser (no IE8 please!) to localhost:9999</li>
  <li>You should be able to see the viz on your browser now! </li>
  <li>Get your own table and make your own viz. </li>
  <li>Once you are happy with your results you can post it to a Github Gist, and point to it from bl.ocks.org as I have done <a href="http://bl.ocks.org/datamusing/d353dd63e013448727b4">here</a>. </li>
</ul>

<p>~ FIN ~ </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On a Mission, in the Mission]]></title>
    <link href="http://datamusing.github.io/blog/2014/08/02/on-a-mission/"/>
    <updated>2014-08-02T10:17:34-07:00</updated>
    <id>http://datamusing.github.io/blog/2014/08/02/on-a-mission</id>
    <content type="html"><![CDATA[<h3 id="or-how-i-leveraged-machine-learning-to-find-must-try-dishes-in-my-neighborhood"><em>or, how I leveraged machine learning to find must try dishes in my neighborhood!</em></h3>

<p>SAN FRANCISCO, CA — Whether its the yummy <em>focaccia de recco</em> at <strong>Farina</strong>, the scrumptious <em>steak tartare</em> at <strong>Bar Tartine</strong>, the <em>chicken liver mousse</em> at Range, or the absolutely bulletproof <em>sesame fried chicken</em> at <strong>Foreign Cinema</strong> — each fine dining restaurant in the Mission District of San Francisco seems to have something mouthwateringly unique to offer.
 <!--more--> 
<img class="center" src="https://dl.dropboxusercontent.com/u/18915298/blog/mission_food/bar_tartine.jpg" width="750" /></p>

<p>The Mission is my neighborhood.  I endearingly call it  the “SF Foodie Central”, not just because some of the best fine dinning restaurants  happen to be here, but also because smaller, fiercely independent purveyors of fine delicacies like <em>Craftsman &amp; Wolves</em>, <em>Dandelion Chocolate</em>, <em>Tartine Bakery</em>, <em>Bi-Rite Creamery</em>,  <em>Four Barrel Coffee</em>, and <em>Ritual Roasters</em>  keep the food scene vibrant and at its delicious best! And then, there is the Mission Mexican food, which is hands down the best in the city. </p>

<p>So it was quite predictable that when analyzing <a href="http://www.opentable.com">OpenTable</a> diner reviews for a data science concept project, I chose to go after the restaurants in the Mission District first. The result of this analysis is a list of <em>the most talked about dishes</em> in the restaurants. </p>

<p>The impatient readers who do not want the algorithm to stand between them and the dishes can scroll down straight to the bottom of the page where all will be revealed.  The inquisitive ones please read on. </p>

<h2 id="an-overview-of-the-algorithm">An overview of the algorithm</h2>

<p>Before I inundate you with names and pictures of those amazing dishes, let me get through the crux of the algorithm as quickly as possible. </p>

<p><img src="https://dl.dropboxusercontent.com/u/18915298/blog/mission_food/brunch.png" width="400" /></p>

<p>The first insight I wanted glean from the huge amount of reviews we have was the set of  main themes, or <em>topics</em> that people are talking about. That is done with a method called <em>topic analysis</em>, for which I used non-negative matrix factorization (NMF) as the main technique (I will write more about the nuances of the method in a future post).  A topic, is essentially a coherent collection of words - or a distribution of over words in the vocabulary. The top words in the <strong>brunch</strong> topic, e.g. may look like the one on the right. It is almost magical to see how words like  <em>brunch, sunday, eggs, benedict, omelette, poached, mimosa, hash, brown</em> and so forth come together into a tightly thematic topic that is readily interpretable. Topic analysis gave me topics for food, drinks, ambiance, service, and so on. For the menu item hunt that was the main focus of this post,  I concentrated on all the food topics. Note that the way topic analysis works, we obtain as a free byproduct the weight of the topics in each review, and by extension, the weight of each topic for each restaurant; e.g. the seafood topic will have very little weight in a restaurant that serves only meat dishes. Once I had that information, I could then look for the most frequently occurring words, bigrams, and trigrams within the context of the topics that peak at that restaurant, and quickly identify the most mentioned food items. There is some secret sauce that helps me disambiguate different ways reviewers talk about the same dish (e.g., someone says “cellophane noodles”, someone else says “cellophane noodles with crab”, yet another reviewer says “the crab noodles”, but they are all referring to the dish “cellophane noodles with dungeness crab”). 
In the end, you just count up the mappings to the dish item, rank them by number of mentions, and voila, you have the most mentioned dishes! </p>

<p>And now lets turn to the results! </p>

<h2 id="the-goods-delivered">The goods, delivered</h2>

<p>Although for each restaurant in the Mission, I could surface multiple dishes, I decided to only show the top (as in most mentioned) dish per restaurant. Note that this is very beta, and we can do so much more in terms of actually figuring out if the dish is being talked about in a positive manner and then count it in, etc. Those will come in due course! Meanwhile, here are the results (<em>scroll to center the iframe on your screen and scroll within the frame from one restaurant to the next</em>).  ENJOY! </p>

<iframe width="100%" height="768" frameborder="0" src="http://bl.ocks.org/anonymous/raw/dde021cbd234a015c111" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="" oallowfullscreen="" msallowfullscreen=""></iframe>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Detecting People in Photographs Using Skin Tone]]></title>
    <link href="http://datamusing.github.io/blog/2014/07/06/detecting-people-in-photographs-using-skin-tone/"/>
    <updated>2014-07-06T00:26:21-07:00</updated>
    <id>http://datamusing.github.io/blog/2014/07/06/detecting-people-in-photographs-using-skin-tone</id>
    <content type="html"><![CDATA[<p>SAN FRANCISCO, CA — As a Data Scientist at <a href="http://opentable.com">OpenTable</a>, my computer screen often fills up with images of scrumptious food items (<em>effectively keeping my metabolic rate on  a high gear!</em>). Many of these photographs are professionally or semi-professionally taken by food photographers or enthusiasts (aka FoodSpotters!).   <!--more--> </p>

<p><img src="https://dl.dropboxusercontent.com/u/18915298/blog/detectSkin/tea-party.jpg" /> </p>

<p>Annoyingly, a lot of photos, especially those from social media channels,  come with portraits of eaters posing with the eaten, such as the one shown here.   Of course, one could use face detection algorithms, and other sophisticated techniques to weed out these photos. These techniques often require a lot of overhead and dependency on external libraries. Also, there may not even be a face in the photo to detect, but a hand or some portion of the torso might be showing. Over the weekend, I have been thinking about very fast ways of finding a human subject in a photograph, so that I could generate some quick features for classifying photos. It turns out that one promising way to do that could be to detect human skin pixels in the photos. </p>

<h2 id="detecting-skin-pixels"><em>Detecting skin pixels</em></h2>

<p>A quick digging into the subject of detecting skin pixels revealed a rich literature on this subject. As this is a blog post and not a review paper, I will only describe the bits I used, and leave the reader with this <a href="http://academic.aua.am/Skhachat/Public/Papers%20on%20Face%20Detection/Survey%20on%20Skin%20Color%20Techniques.pdf">paper</a> or <a href="http://pdf.aminer.org/000/367/151/image_chromatic_adaptation_using_anns_for_skin_color_adaptation.pdf">this one</a> as an entry point into this subject. <em>The fundamental concept behind pixel based skin detection is that the color of human skin (across various races and ethnicities) occupies a very tight region in the space of colors.</em>  In brief, there are three main ways to detect skin pixels: </p>

<ol>
  <li><strong>Explicit Skin Model Based Method</strong>:  This class of methods try to use machine learning to find the best colorspace and a simple decision rule to define the boundaries the skin cluster in that colorspace. </li>
  <li><strong>Non-parametric Methods</strong>:  The key idea here is to estimate skin color distribution from a training data without deriving an explicit model of the skin color, e.g. a Naive-Bayes classifier. A skin/non-skin training data set can be found <a href="https://archive.ics.uci.edu/ml/datasets/Skin+Segmentation">here</a>.</li>
  <li><strong>Parametric Methods</strong>:  Here, one models the skin color distributions as parameterized probability distributions, such as Gaussians, or mixtures of Gaussians.</li>
</ol>

<p>As a first stab, I decided to go with method (1) above. A little more investigation led me to the  <a href="http://www.cse.unsw.edu.au/~tatjana/ICMLWS02/MLCV/Morales.pdf">Gomez and Morales (2002)</a> paper where the authors used a constructive induction algorithm which produces a single rule that defines the skin color boundary conditions in the RGB colorspace. Their method leads to an  extremely simple rule that goes as follows: </p>

<ul>
  <li>Extract R, G, B pixel values from the input image. </li>
  <li>Normalize:  <script type="math/tex">r=R/(R+G+B)</script>,   <script type="math/tex">g=G/(R+G+B)</script> and <script type="math/tex">b=B/(R+G+B)</script>, so that <script type="math/tex">(r+g+b) = 1</script> for each pixel.</li>
  <li>Next, generate three quantities (note that $(r+g+b)$ being unity is redundant here, but the authors probably left it in to make the normalization explicit): </li>
</ul>

<script type="math/tex; mode=display">% &lt;![CDATA[
  
\begin{eqnarray}
	\alpha &=& \frac{3b r^2}{(r+g+b)^3}\\
	\beta &=& \frac{r+g+b}{3r} + \frac{r-g}{r+g+b}	\\
	\gamma &=& \frac{r b+g^2}{g b}
\end{eqnarray}
 %]]&gt;</script>

<ul>
  <li>Finally, a pixel is categorized as “skin” if the pixel satisfies <strong>all</strong> of the following three conditions: </li>
</ul>

<p><script type="math/tex"> \alpha>0.1276</script>, <script type="math/tex">\beta \le 0.9498</script> and  <script type="math/tex">\gamma \le 2.7775 </script>.</p>

<p>Note that these rules were based on the training set available when the paper was written, and I should probably be regenerating the rules with more training examples available now. But, the color of skin has not changed significantly in 10 years, so lets continue! </p>

<p>Here is a quick Python implementation:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">matplotlib.image</span> <span class="kn">as</span> <span class="nn">mpimg</span>
</span><span class="line"><span class="c"># read in the image</span>
</span><span class="line"><span class="n">values</span> <span class="o">=</span> <span class="n">mpimg</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s">&quot;tea-party.jpg&quot;</span><span class="p">)</span>
</span><span class="line"><span class="c"># separate out r, g, b channels</span>
</span><span class="line"><span class="n">r</span> <span class="o">=</span> <span class="n">values</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">&#39;f&#39;</span><span class="p">)</span>
</span><span class="line"><span class="n">g</span> <span class="o">=</span> <span class="n">values</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">&#39;f&#39;</span><span class="p">)</span>
</span><span class="line"><span class="n">b</span> <span class="o">=</span> <span class="n">values</span><span class="p">[:,:,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">&#39;f&#39;</span><span class="p">)</span>
</span><span class="line"><span class="c"># generate the three quantities </span>
</span><span class="line"><span class="n">alpha</span> <span class="o">=</span> <span class="mi">3</span><span class="o">*</span><span class="n">b</span><span class="o">*</span><span class="n">r</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">r</span><span class="o">+</span><span class="n">b</span><span class="o">+</span><span class="n">g</span><span class="p">)</span><span class="o">**</span><span class="mi">3</span>
</span><span class="line"><span class="n">beta</span> <span class="o">=</span>  <span class="p">(</span><span class="n">r</span><span class="o">+</span><span class="n">g</span><span class="o">+</span><span class="n">b</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">r</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">r</span><span class="o">-</span><span class="n">g</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">r</span><span class="o">+</span><span class="n">g</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>
</span><span class="line"><span class="n">gamma</span> <span class="o">=</span> <span class="p">(</span><span class="n">r</span><span class="o">*</span><span class="n">b</span><span class="o">+</span><span class="n">g</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">g</span><span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span><span class="line"><span class="c"># finally we apply the rules:</span>
</span><span class="line"><span class="n">pylab</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="n">alpha</span><span class="o">&gt;</span><span class="mf">0.1276</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">beta</span><span class="o">&lt;=</span><span class="mf">0.9498</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">gamma</span><span class="o">&lt;=</span><span class="mf">2.7775</span><span class="p">),</span><span class="n">cmap</span><span class="o">=</span><span class="s">&#39;gray&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>which gives us the following result, where white represents pixels labeled as skin (the original image is also below for easy comparison):<br />
<img class="center" src="https://dl.dropboxusercontent.com/u/18915298/blog/detectSkin/tea_party_binary.png" width="300" height="300" /></p>

<p><img class="center" src="https://dl.dropboxusercontent.com/u/18915298/blog/detectSkin/tea-party.jpg" width="300" height="300" /></p>

<p>As  you can see, this one simple rule does remarkably well in isolating skin pixels. </p>

<p>Here is another example:</p>

<p><img class="center" src="https://dl.dropboxusercontent.com/u/18915298/blog/detectSkin/slanted_door_comp.png" /></p>
]]></content>
  </entry>
  
</feed>
